{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "110/110 [==============================] - 25s 214ms/step - loss: 0.1714 - accuracy: 0.9418 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "110/110 [==============================] - 23s 206ms/step - loss: 4.0019e-04 - accuracy: 1.0000 - val_loss: 1.0629e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "110/110 [==============================] - 24s 221ms/step - loss: 5.6755e-05 - accuracy: 1.0000 - val_loss: 6.8253e-05 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "110/110 [==============================] - 24s 216ms/step - loss: 3.4061e-05 - accuracy: 1.0000 - val_loss: 4.9915e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "110/110 [==============================] - 23s 211ms/step - loss: 2.2795e-05 - accuracy: 1.0000 - val_loss: 3.9717e-05 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "110/110 [==============================] - 24s 216ms/step - loss: 1.6250e-05 - accuracy: 1.0000 - val_loss: 3.1561e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "110/110 [==============================] - 24s 217ms/step - loss: 1.2440e-05 - accuracy: 1.0000 - val_loss: 2.4417e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "110/110 [==============================] - 24s 216ms/step - loss: 9.7201e-06 - accuracy: 1.0000 - val_loss: 2.0516e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "110/110 [==============================] - 25s 229ms/step - loss: 7.6559e-06 - accuracy: 1.0000 - val_loss: 1.7560e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "110/110 [==============================] - 25s 225ms/step - loss: 6.2940e-06 - accuracy: 1.0000 - val_loss: 1.6149e-05 - val_accuracy: 1.0000\n",
      "28/28 [==============================] - 1s 49ms/step - loss: 1.6149e-05 - accuracy: 1.0000\n",
      "Test Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Function to load images and labels\n",
    "def load_data(data_dir):\n",
    "    images = []\n",
    "    labels = []\n",
    "    class_names = os.listdir(data_dir)\n",
    "    num_classes = len(class_names)\n",
    "    \n",
    "    for i, class_name in enumerate(class_names):\n",
    "        class_dir = os.path.join(data_dir, class_name)\n",
    "        for image_name in os.listdir(class_dir):\n",
    "            image_path = os.path.join(class_dir, image_name)\n",
    "            image = cv2.imread(image_path)\n",
    "            image = cv2.resize(image, (100, 100))  \n",
    "            images.append(image)\n",
    "            labels.append(i)\n",
    "    \n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    return images, labels, num_classes\n",
    "\n",
    "# Load dataset\n",
    "data_dir = \"C:/Users/avi11/Downloads/Classification/Train\"  \n",
    "images, labels, num_classes = load_data(data_dir)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess data\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "# Build CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\avi11\\AppData\\Local\\Temp\\tmpw2yvu2v1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\avi11\\AppData\\Local\\Temp\\tmpw2yvu2v1\\assets\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "\n",
    "model.save(\"classification_model.h5\")\n",
    "# Load the Keras model\n",
    "model = load_model(\"classification_model.h5\")\n",
    "\n",
    "# Convert the model to TFLite format\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TFLite model to file\n",
    "with open(\"model.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "342/342 [==============================] - 78s 224ms/step - loss: 0.5955 - accuracy: 0.7927 - val_loss: 0.2912 - val_accuracy: 0.9104\n",
      "Epoch 2/10\n",
      "342/342 [==============================] - 77s 225ms/step - loss: 0.2153 - accuracy: 0.9329 - val_loss: 0.2486 - val_accuracy: 0.9137\n",
      "Epoch 3/10\n",
      "342/342 [==============================] - 78s 227ms/step - loss: 0.1410 - accuracy: 0.9515 - val_loss: 0.1589 - val_accuracy: 0.9473\n",
      "Epoch 4/10\n",
      "342/342 [==============================] - 77s 226ms/step - loss: 0.1031 - accuracy: 0.9663 - val_loss: 0.2240 - val_accuracy: 0.9265\n",
      "Epoch 5/10\n",
      "342/342 [==============================] - 78s 229ms/step - loss: 0.0667 - accuracy: 0.9769 - val_loss: 0.1674 - val_accuracy: 0.9546\n",
      "Epoch 6/10\n",
      "342/342 [==============================] - 76s 222ms/step - loss: 0.0469 - accuracy: 0.9840 - val_loss: 0.1553 - val_accuracy: 0.9576\n",
      "Epoch 7/10\n",
      "342/342 [==============================] - 77s 226ms/step - loss: 0.0472 - accuracy: 0.9844 - val_loss: 0.1623 - val_accuracy: 0.9546\n",
      "Epoch 8/10\n",
      "342/342 [==============================] - 79s 231ms/step - loss: 0.0357 - accuracy: 0.9873 - val_loss: 0.2024 - val_accuracy: 0.9572\n",
      "Epoch 9/10\n",
      "342/342 [==============================] - 76s 221ms/step - loss: 0.0355 - accuracy: 0.9890 - val_loss: 0.1569 - val_accuracy: 0.9653\n",
      "Epoch 10/10\n",
      "342/342 [==============================] - 81s 237ms/step - loss: 0.0228 - accuracy: 0.9923 - val_loss: 0.2222 - val_accuracy: 0.9466\n",
      "86/86 [==============================] - 5s 55ms/step - loss: 0.2222 - accuracy: 0.9466\n",
      "Test Accuracy: 0.9465984106063843\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Function to load images and labels\n",
    "def load_data(data_dir):\n",
    "    images = []\n",
    "    labels = []\n",
    "    class_names = os.listdir(data_dir)\n",
    "    num_classes = len(class_names)\n",
    "    \n",
    "    for class_name in class_names:\n",
    "        class_dir = os.path.join(data_dir, class_name)\n",
    "        subfolders = os.listdir(class_dir)\n",
    "        for subfolder in subfolders:\n",
    "            subfolder_dir = os.path.join(class_dir, subfolder)\n",
    "            for image_name in os.listdir(subfolder_dir):\n",
    "                image_path = os.path.join(subfolder_dir, image_name)\n",
    "                image = cv2.imread(image_path)\n",
    "                image = cv2.resize(image, (100, 100))  # Resize images to a fixed size\n",
    "                images.append(image)\n",
    "                labels.append(class_names.index(class_name))  # Use index of class name as label\n",
    "    \n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    return images, labels, num_classes\n",
    "\n",
    "# Load dataset\n",
    "data_dir = \"C:/Users/avi11/Downloads/Dataset\"  \n",
    "images, labels, num_classes = load_data(data_dir)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess data\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "# Build CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\avi11\\AppData\\Local\\Temp\\tmpbwjmz7ku\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\avi11\\AppData\\Local\\Temp\\tmpbwjmz7ku\\assets\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "\n",
    "model.save(\"grading_model.h5\")\n",
    "# Load the Keras model\n",
    "model = load_model(\"grading_model.h5\")\n",
    "\n",
    "# Convert the model to TFLite format\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TFLite model to file\n",
    "with open(\"model.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Function to load images and labels\n",
    "def load_data(data_dir):\n",
    "    images = []\n",
    "    labels = []\n",
    "    class_names = os.listdir(data_dir)\n",
    "    num_classes = len(class_names)\n",
    "    \n",
    "    for class_name in class_names:\n",
    "        class_dir = os.path.join(data_dir, class_name)\n",
    "        subfolders = os.listdir(class_dir)\n",
    "        for subfolder in subfolders:\n",
    "            subfolder_dir = os.path.join(class_dir, subfolder)\n",
    "            for image_name in os.listdir(subfolder_dir):\n",
    "                image_path = os.path.join(subfolder_dir, image_name)\n",
    "                image = cv2.imread(image_path)\n",
    "                image = cv2.resize(image, (100, 100))  # Resize images to a fixed size\n",
    "                images.append(image)\n",
    "                labels.append(1 if subfolder == 'rotten' else 0)  # 1 for rotten, 0 for fresh\n",
    "    \n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    return images, labels, num_classes\n",
    "\n",
    "# Load dataset\n",
    "data_dir = \"C:/Users/avi11/Downloads/Dataset\"  \n",
    "images, labels, num_classes = load_data(data_dir)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess data\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "y_train = to_categorical(y_train, 2)  # Use 2 classes: rotten or fresh\n",
    "y_test = to_categorical(y_test, 2)\n",
    "\n",
    "# Build CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(2, activation='softmax')  # 2 output classes: rotten or fresh\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
